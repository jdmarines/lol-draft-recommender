# -*- coding: utf-8 -*-
"""draft_recommender

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19rH2Y4VvqxqLG2hMZTl79_j9NRaalHVd
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split

# Campeones y líneas
campeones = ['Lee Sin', 'Jax', 'Kai\'Sa', 'Viktor', 'Thresh', 'Zed', 'Lux', 'Ashe', 'Ezreal', 'Graves']
lineas = ['Top', 'Jungle', 'Mid', 'Bot', 'Support']

# Datos de winrates (valores de ejemplo, reemplazar por datos reales)
winrate_data = {
    'Lee Sin': {'Top': 51.2, 'Jungle': 53.2, 'Mid': 50.1, 'Bot': 49.5, 'Support': 47.5},
    'Jax': {'Top': 52.3, 'Jungle': 50.1, 'Mid': 48.3, 'Bot': 47.9, 'Support': 46.5},
    'Kai\'Sa': {'Top': 50.8, 'Jungle': 52.5, 'Mid': 53.2, 'Bot': 54.1, 'Support': 50.9},
    'Viktor': {'Top': 51.5, 'Jungle': 51.8, 'Mid': 55.2, 'Bot': 49.7, 'Support': 48.3},
    'Thresh': {'Top': 49.9, 'Jungle': 49.8, 'Mid': 50.2, 'Bot': 52.3, 'Support': 55.6},
    'Zed': {'Top': 52.0, 'Jungle': 50.2, 'Mid': 54.3, 'Bot': 48.5, 'Support': 46.0},
    'Lux': {'Top': 48.5, 'Jungle': 50.0, 'Mid': 53.3, 'Bot': 49.0, 'Support': 55.1},
    'Ashe': {'Top': 47.9, 'Jungle': 48.6, 'Mid': 49.5, 'Bot': 53.7, 'Support': 50.8},
    'Ezreal': {'Top': 49.6, 'Jungle': 50.1, 'Mid': 52.0, 'Bot': 55.4, 'Support': 48.2},
    'Graves': {'Top': 50.2, 'Jungle': 54.0, 'Mid': 52.6, 'Bot': 49.8, 'Support': 47.7}
}

# Datos de sinergias (valores de ejemplo, entre 0 y 1)
sinergia_data = {
    'Lee Sin': {'Jax': 0.7, 'Kai\'Sa': 0.8, 'Viktor': 0.6, 'Thresh': 0.9, 'Zed': 0.7, 'Lux': 0.5, 'Ashe': 0.6, 'Ezreal': 0.7, 'Graves': 0.8},
    'Jax': {'Lee Sin': 0.7, 'Kai\'Sa': 0.6, 'Viktor': 0.7, 'Thresh': 0.8, 'Zed': 0.6, 'Lux': 0.7, 'Ashe': 0.5, 'Ezreal': 0.6, 'Graves': 0.6},
    'Kai\'Sa': {'Lee Sin': 0.8, 'Jax': 0.6, 'Viktor': 0.7, 'Thresh': 0.9, 'Zed': 0.8, 'Lux': 0.6, 'Ashe': 0.7, 'Ezreal': 0.8, 'Graves': 0.7},
    'Viktor': {'Lee Sin': 0.6, 'Jax': 0.7, 'Kai\'Sa': 0.7, 'Thresh': 0.6, 'Zed': 0.6, 'Lux': 0.8, 'Ashe': 0.6, 'Ezreal': 0.7, 'Graves': 0.6},
    'Thresh': {'Lee Sin': 0.9, 'Jax': 0.8, 'Kai\'Sa': 0.9, 'Viktor': 0.6, 'Zed': 0.7, 'Lux': 0.7, 'Ashe': 0.8, 'Ezreal': 0.9, 'Graves': 0.8},
    'Zed': {'Lee Sin': 0.7, 'Jax': 0.6, 'Kai\'Sa': 0.8, 'Viktor': 0.6, 'Thresh': 0.6, 'Lux': 0.5, 'Ashe': 0.7, 'Ezreal': 0.6, 'Graves': 0.7},
    'Lux': {'Lee Sin': 0.5, 'Jax': 0.7, 'Kai\'Sa': 0.6, 'Viktor': 0.8, 'Thresh': 0.7, 'Zed': 0.5, 'Ashe': 0.7, 'Ezreal': 0.8, 'Graves': 0.6},
    'Ashe': {'Lee Sin': 0.6, 'Jax': 0.5, 'Kai\'Sa': 0.7, 'Viktor': 0.6, 'Thresh': 0.8, 'Zed': 0.7, 'Lux': 0.7, 'Ezreal': 0.9, 'Graves': 0.7},
    'Ezreal': {'Lee Sin': 0.7, 'Jax': 0.6, 'Kai\'Sa': 0.8, 'Viktor': 0.7, 'Thresh': 0.9, 'Zed': 0.6, 'Lux': 0.8, 'Ashe': 0.9, 'Graves': 0.7},
    'Graves': {'Lee Sin': 0.8, 'Jax': 0.6, 'Kai\'Sa': 0.7, 'Viktor': 0.6, 'Thresh': 0.8, 'Zed': 0.7, 'Lux': 0.6, 'Ashe': 0.7, 'Ezreal': 0.7}
}

# Embeddings de campeones (valores aleatorios entre -1 y 1)
embeddings_data = {
    'Lee Sin': [0.1, 0.2, 0.3],
    'Jax': [0.2, 0.3, 0.4],
    'Kai\'Sa': [0.3, 0.4, 0.5],
    'Viktor': [0.4, 0.5, 0.6],
    'Thresh': [0.5, 0.6, 0.7],
    'Zed': [0.6, 0.7, 0.8],
    'Lux': [0.7, 0.8, 0.9],
    'Ashe': [0.8, 0.9, 1.0],
    'Ezreal': [0.9, 1.0, 0.8],
    'Graves': [1.0, 0.9, 0.7]
}

# Generación del DataFrame con todos los campeones, líneas y características
rows = []
for campeon in campeones:
    for linea in lineas:
        row = {
            'Campeon': campeon,
            'Linea': linea,
            'Winrate': winrate_data[campeon][linea],
            'Sinergia': sum(sinergia_data[campeon].values()) / len(sinergia_data[campeon]),
            'Counter': sum([counter for counter in sinergia_data[campeon].values()]) / len(sinergia_data[campeon]),
            'Embedding_1': embeddings_data[campeon][0],
            'Embedding_2': embeddings_data[campeon][1],
            'Embedding_3': embeddings_data[campeon][2]
        }
        rows.append(row)

df = pd.DataFrame(rows)

# Mostrar el DataFrame
print(df)

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Datos de ejemplo, usando los datos anteriores (como base)
campeones = ['Lee Sin', 'Jax', 'Kai\'Sa', 'Viktor', 'Thresh', 'Zed', 'Lux', 'Ashe', 'Ezreal', 'Graves']
lineas = ['Top', 'Jungle', 'Mid', 'Bot', 'Support']

# Winrate, Sinergia, Counter, Embeddings y otras características generadas previamente
winrate_data = {
    'Lee Sin': {'Top': 51.2, 'Jungle': 53.2, 'Mid': 50.1, 'Bot': 49.5, 'Support': 47.5},
    'Jax': {'Top': 52.3, 'Jungle': 50.1, 'Mid': 48.3, 'Bot': 47.9, 'Support': 46.5},
    'Kai\'Sa': {'Top': 50.8, 'Jungle': 52.5, 'Mid': 53.2, 'Bot': 54.1, 'Support': 50.9},
    'Viktor': {'Top': 51.5, 'Jungle': 51.8, 'Mid': 55.2, 'Bot': 49.7, 'Support': 48.3},
    'Thresh': {'Top': 49.9, 'Jungle': 49.8, 'Mid': 50.2, 'Bot': 52.3, 'Support': 55.6},
    'Zed': {'Top': 52.0, 'Jungle': 50.2, 'Mid': 54.3, 'Bot': 48.5, 'Support': 46.0},
    'Lux': {'Top': 48.5, 'Jungle': 50.0, 'Mid': 53.3, 'Bot': 49.0, 'Support': 55.1},
    'Ashe': {'Top': 47.9, 'Jungle': 48.6, 'Mid': 49.5, 'Bot': 53.7, 'Support': 50.8},
    'Ezreal': {'Top': 49.6, 'Jungle': 50.1, 'Mid': 52.0, 'Bot': 55.4, 'Support': 48.2},
    'Graves': {'Top': 50.2, 'Jungle': 54.0, 'Mid': 52.6, 'Bot': 49.8, 'Support': 47.7}
}

# Sinergia (promedio con otros campeones)
sinergia_data = {
    'Lee Sin': {'Jax': 0.7, 'Kai\'Sa': 0.8, 'Viktor': 0.6, 'Thresh': 0.9, 'Zed': 0.7, 'Lux': 0.5, 'Ashe': 0.6, 'Ezreal': 0.7, 'Graves': 0.8},
    'Jax': {'Lee Sin': 0.7, 'Kai\'Sa': 0.6, 'Viktor': 0.7, 'Thresh': 0.8, 'Zed': 0.6, 'Lux': 0.7, 'Ashe': 0.5, 'Ezreal': 0.6, 'Graves': 0.6},
    'Kai\'Sa': {'Lee Sin': 0.8, 'Jax': 0.6, 'Viktor': 0.7, 'Thresh': 0.9, 'Zed': 0.8, 'Lux': 0.6, 'Ashe': 0.7, 'Ezreal': 0.8, 'Graves': 0.7},
    'Viktor': {'Lee Sin': 0.6, 'Jax': 0.7, 'Kai\'Sa': 0.7, 'Thresh': 0.6, 'Zed': 0.6, 'Lux': 0.8, 'Ashe': 0.6, 'Ezreal': 0.7, 'Graves': 0.6},
    'Thresh': {'Lee Sin': 0.9, 'Jax': 0.8, 'Kai\'Sa': 0.9, 'Viktor': 0.6, 'Zed': 0.7, 'Lux': 0.7, 'Ashe': 0.8, 'Ezreal': 0.9, 'Graves': 0.8},
    'Zed': {'Lee Sin': 0.7, 'Jax': 0.6, 'Kai\'Sa': 0.8, 'Viktor': 0.6, 'Thresh': 0.6, 'Lux': 0.5, 'Ashe': 0.7, 'Ezreal': 0.6, 'Graves': 0.7},
    'Lux': {'Lee Sin': 0.5, 'Jax': 0.7, 'Kai\'Sa': 0.6, 'Viktor': 0.8, 'Thresh': 0.7, 'Zed': 0.5, 'Ashe': 0.7, 'Ezreal': 0.8, 'Graves': 0.6},
    'Ashe': {'Lee Sin': 0.6, 'Jax': 0.5, 'Kai\'Sa': 0.7, 'Viktor': 0.6, 'Thresh': 0.8, 'Zed': 0.7, 'Lux': 0.7, 'Ezreal': 0.9, 'Graves': 0.7},
    'Ezreal': {'Lee Sin': 0.7, 'Jax': 0.6, 'Kai\'Sa': 0.8, 'Viktor': 0.7, 'Thresh': 0.9, 'Zed': 0.6, 'Lux': 0.8, 'Ashe': 0.9, 'Graves': 0.7},
    'Graves': {'Lee Sin': 0.8, 'Jax': 0.6, 'Kai\'Sa': 0.7, 'Viktor': 0.6, 'Thresh': 0.8, 'Zed': 0.7, 'Lux': 0.6, 'Ashe': 0.7, 'Ezreal': 0.7}
}

# Embeddings de campeones
embeddings_data = {
    'Lee Sin': [0.1, 0.2, 0.3],
    'Jax': [0.2, 0.3, 0.4],
    'Kai\'Sa': [0.3, 0.4, 0.5],
    'Viktor': [0.4, 0.5, 0.6],
    'Thresh': [0.5, 0.6, 0.7],
    'Zed': [0.6, 0.7, 0.8],
    'Lux': [0.7, 0.8, 0.9],
    'Ashe': [0.8, 0.9, 1.0],
    'Ezreal': [0.9, 1.0, 0.8],
    'Graves': [1.0, 0.9, 0.7]
}

# Preparar el DataFrame completo
rows = []
for campeon in campeones:
    for linea in lineas:
        row = {
            'Campeon': campeon,
            'Linea': linea,
            'Winrate': winrate_data[campeon][linea],
            'Sinergia': sum(sinergia_data[campeon].values()) / len(sinergia_data[campeon]),
            'Counter': sum([counter for counter in sinergia_data[campeon].values()]) / len(sinergia_data[campeon]),
            'Embedding_1': embeddings_data[campeon][0],
            'Embedding_2': embeddings_data[campeon][1],
            'Embedding_3': embeddings_data[campeon][2]
        }
        rows.append(row)

df = pd.DataFrame(rows)

# Preprocesar las características
X = df[['Winrate', 'Sinergia', 'Counter', 'Embedding_1', 'Embedding_2', 'Embedding_3']]
y = df['Campeon']

# Codificar las líneas y campeones (target)
y = pd.Categorical(y).codes  # Convertir campeones en valores numéricos

# Dividir los datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar el modelo XGBoost
model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
model.fit(X_train, y_train)

# Realizar predicciones
y_pred = model.predict(X_test)

# Evaluar el modelo
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy del modelo: {accuracy:.2f}")

# Ejemplo de predicción
campeon_pred = model.predict([X.iloc[0]])
print(f"Predicción para el primer campeón: {df.iloc[0]['Campeon']} -> Predicción: {campeon_pred}")

pip install streamlit

import streamlit as st
import pandas as pd
import numpy as np
import xgboost as xgb

# Definir los campeones y sus características
campeones = ['Lee Sin', 'Jax', 'Kai\'Sa', 'Viktor', 'Thresh', 'Zed', 'Lux', 'Ashe', 'Ezreal', 'Graves']
lineas = ['Top', 'Jungle', 'Mid', 'Bot', 'Support']

# Datos simulados de campeones (winrate, sinergia, counter y embeddings)
campeon_data = {
    'Lee Sin': {'Winrate': 53.2, 'Sinergia': 0.7, 'Counter': 0.6, 'Embedding_1': 0.1, 'Embedding_2': 0.2, 'Embedding_3': 0.3},
    'Jax': {'Winrate': 52.3, 'Sinergia': 0.8, 'Counter': 0.7, 'Embedding_1': 0.2, 'Embedding_2': 0.3, 'Embedding_3': 0.4},
    'Kai\'Sa': {'Winrate': 54.1, 'Sinergia': 0.6, 'Counter': 0.7, 'Embedding_1': 0.3, 'Embedding_2': 0.4, 'Embedding_3': 0.5},
    'Viktor': {'Winrate': 55.2, 'Sinergia': 0.8, 'Counter': 0.7, 'Embedding_1': 0.4, 'Embedding_2': 0.5, 'Embedding_3': 0.6},
    'Thresh': {'Winrate': 51.5, 'Sinergia': 0.7, 'Counter': 0.6, 'Embedding_1': 0.3, 'Embedding_2': 0.4, 'Embedding_3': 0.4},
    'Zed': {'Winrate': 55.8, 'Sinergia': 0.6, 'Counter': 0.8, 'Embedding_1': 0.2, 'Embedding_2': 0.3, 'Embedding_3': 0.5},
    'Lux': {'Winrate': 53.0, 'Sinergia': 0.7, 'Counter': 0.6, 'Embedding_1': 0.1, 'Embedding_2': 0.2, 'Embedding_3': 0.3},
    'Ashe': {'Winrate': 54.3, 'Sinergia': 0.7, 'Counter': 0.6, 'Embedding_1': 0.2, 'Embedding_2': 0.3, 'Embedding_3': 0.4},
    'Ezreal': {'Winrate': 55.1, 'Sinergia': 0.8, 'Counter': 0.6, 'Embedding_1': 0.3, 'Embedding_2': 0.4, 'Embedding_3': 0.5},
    'Graves': {'Winrate': 53.5, 'Sinergia': 0.7, 'Counter': 0.6, 'Embedding_1': 0.2, 'Embedding_2': 0.3, 'Embedding_3': 0.4},
}

# Función para obtener las características de un campeón
def get_champion_data(champion):
    return campeon_data[champion]

# Crear un dataframe de ejemplo con el estado de draft
estado_draft = {
    1: ['Lee Sin'],  # Ejemplo: Turno 1 - Lee Sin es seleccionado
    2: ['Lee Sin', 'Jax'],  # Turno 2 - Lee Sin y Jax seleccionados
    3: ['Lee Sin', 'Jax', 'Kai\'Sa'],  # Turno 3 - Lee Sin, Jax, Kai'Sa seleccionados
}

# Preprocesar datos para el modelo
def preprocess_data(state_draft):
    # Crear un vector de 0s y 1s para representar los campeones seleccionados
    draft_vector = [1 if champ in state_draft else 0 for champ in campeones]
    # Obtener las características (winrate, sinergia, counter, embeddings) para el próximo campeón
    features = []
    for champ in campeones:
        features.append(list(get_champion_data(champ).values()))
    return draft_vector, features

# Entrenamiento básico con XGBoost (simulado)
def train_xgboost_model():
    # Simulate training with dummy data
    X = np.random.rand(10, 6)  # 10 champions, 6 features (winrate, synergy, counter, embeddings)
    # Ensure y contains all classes from 0 to len(campeones) - 1
    y = np.arange(len(campeon_data))
    # Create the XGBoost model
    model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    # Fit the model
    model.fit(X, y)
    # Return the trained model
    return model
# Entrenar el modelo (esto se debe hacer una vez, pero por ahora lo hacemos al inicio)
model = train_xgboost_model()

# Función para predecir el próximo campeón
def predict_next_champion(state_draft):
    draft_vector, features = preprocess_data(state_draft)

    # Get features for all champions
    all_champion_features = np.array(features)

    #*** Instead of repeating the draft vector, we use it to select features
    #*** for the champions currently in the draft
    #*** and then predict the probabilities for the remaining champions
    selected_champion_indices = [campeones.index(champ) for champ in state_draft]
    remaining_champion_indices = [i for i in range(len(campeones)) if i not in selected_champion_indices]

    # Features for champions in the draft
    draft_features = all_champion_features[selected_champion_indices]

    # Features for the remaining champions
    remaining_features = all_champion_features[remaining_champion_indices]

    # Predict probabilities for remaining champions
    predictions = model.predict_proba(remaining_features)

    # Get the index of the champion with the highest probability among remaining champions
    predicted_index = np.argmax(predictions)

    # Return the name of the predicted champion
    return campeones[remaining_champion_indices[predicted_index]]

# Interfaz de usuario interactiva con Streamlit
st.title('Sistema de Recomendación de Draft - League of Legends')

# Selección de campeones ya elegidos
state_draft = []
for i in range(5):  # Permitir seleccionar hasta 5 campeones
    selected_champ = st.selectbox(f"Selecciona un campeón para el turno {i+1}", campeones, key=f"champ_{i}")
    if selected_champ:
        state_draft.append(selected_champ)

# Mostrar el estado actual del draft
st.write("Estado actual del draft:", state_draft)

# Predecir el siguiente campeón
if len(state_draft) > 0:
    next_champion = predict_next_champion(state_draft)
    st.write(f"Recomendación para el siguiente campeón: {next_champion}")